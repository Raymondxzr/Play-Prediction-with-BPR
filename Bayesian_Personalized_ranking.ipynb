{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57bb1c66-8319-4e09-a19d-dda33009d678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:07:04.253730: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8bb02b6-6a06-4d51-8df0-3250fbfd76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fe7e59-6a9a-4e48-852c-1d988c37576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb89d9f6-4c6d-4ce5-932b-5c46c39ef694",
   "metadata": {},
   "outputs": [],
   "source": [
    "allHours = []\n",
    "for l in readJSON(\"train.json.gz\"):\n",
    "    allHours.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9179d2-1c83-4d24-bbc8-36f2b5f4fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoursTrain = allHours[:165000]\n",
    "hoursValid = allHours[165000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a22254-30ad-4496-ac56-f1a863181998",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games = [d[1] for d in allHours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f7dfec-9c55-41c2-9c98-334e83d57280",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_games = defaultdict(set)\n",
    "for u,i,d in allHours:\n",
    "    user_games[u].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc285b26-67ce-4388-bf4c-96f7a81bd4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct negative sample randomly for validation\n",
    "hoursValid_with_negatives = []\n",
    "labels = []\n",
    "for userID,itemID,d in hoursValid:\n",
    "    positive_game_id = itemID\n",
    "    negative_game_candidates = list(set(all_games) - user_games[userID])\n",
    "    \n",
    "    if negative_game_candidates:\n",
    "        negative_game_id = random.choice(negative_game_candidates)\n",
    "        \n",
    "        hoursValid_with_negatives.append((userID,itemID,d))\n",
    "        labels.append(1)\n",
    "\n",
    "        hoursValid_with_negatives.append((userID, negative_game_id, {}))\n",
    "        labels.append(0)\n",
    "        \n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf61894-5c71-4b18-98c0-ff2dbfea8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "881b95fa-c089-48e7-afca-0dbc34188a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ug_train = defaultdict(set)\n",
    "gu_train = defaultdict(set)\n",
    "\n",
    "for u,g,_ in hoursTrain:\n",
    "    ug_train[u].add(g)\n",
    "    gu_train[g].add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e219f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bayesian Personalized Ranking (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87e10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from userID and itemID to indices\n",
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "interactions = []\n",
    "for u, g, d in hoursTrain:\n",
    "    r = d['hours_transformed']\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not g in itemIDs: itemIDs[g] = len(itemIDs)\n",
    "    interactions.append((u,g,r))\n",
    "    \n",
    "random.shuffle(interactions)\n",
    "\n",
    "nTrain = int(len(interactions)*0.9)\n",
    "nTest = len(interactions)- nTrain\n",
    "interactionsTrain = interactions[:nTrain]\n",
    "interactionsTest = interactions[nTrain:]\n",
    "\n",
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "\n",
    "for u,i,r in interactionsTrain:\n",
    "    itemsPerUser[u].append(i)\n",
    "    usersPerItem[i].append(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e861c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(itemIDs.keys())\n",
    "class BPRbatch(tf.keras.Model):\n",
    "    def __init__(self, K, lamb):\n",
    "        super(BPRbatch, self).__init__()\n",
    "        # Initialize variables\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        # Regularization coefficient\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance\n",
    "    def predict(self, u, i):\n",
    "        p = self.betaI[i] + tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.nn.l2_loss(self.betaI) +\\\n",
    "                            tf.nn.l2_loss(self.gammaU) +\\\n",
    "                            tf.nn.l2_loss(self.gammaI))\n",
    "    \n",
    "    def score(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        x_ui = beta_i + tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return x_ui\n",
    "\n",
    "    def call(self, sampleU, sampleI, sampleJ):\n",
    "        x_ui = self.score(sampleU, sampleI)\n",
    "        x_uj = self.score(sampleU, sampleJ)\n",
    "        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe41732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStepBPR(model, interactions):\n",
    "    Nsamples = 50000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleJ = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,_ = random.choice(interactions) # positive sample\n",
    "            j = random.choice(items) # negative sample\n",
    "            while j in itemsPerUser[u]:\n",
    "                j = random.choice(items)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleJ.append(itemIDs[j])\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleJ)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a3046a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_would_play(u,i):\n",
    "    user_id = userIDs.get(u, None)\n",
    "    item_id = itemIDs.get(i, None)\n",
    "    \n",
    "    if user_id is not None and item_id is not None:\n",
    "        score = modelBPR.predict(user_id,item_id).numpy()\n",
    "        return score\n",
    "    else:\n",
    "        # default score for unseen user or id\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82e6da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.1\n",
    "K = 5\n",
    "lamb = 1e-5\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9902c27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 00:07:40.271410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10398 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:85:00.0, compute capability: 6.1\n",
      "2023-11-24 00:07:55.295749: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b3516f82c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-24 00:07:55.295793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2023-11-24 00:07:55.303942: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-24 00:07:55.815467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-11-24 00:07:56.058021: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 0.51601505\n",
      "iteration 20, objective = 0.48353913\n",
      "iteration 30, objective = 0.46613118\n",
      "iteration 40, objective = 0.458682\n",
      "iteration 50, objective = 0.45653126\n",
      "iteration 60, objective = 0.45299065\n",
      "iteration 70, objective = 0.45042548\n",
      "iteration 80, objective = 0.44632196\n",
      "iteration 90, objective = 0.44679296\n",
      "iteration 100, objective = 0.4433291\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "modelBPR = BPRbatch(K, lamb)\n",
    "for i in range(iterations):\n",
    "    obj = trainingStepBPR(modelBPR, interactions)\n",
    "    if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "622518df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19998/19998 [00:50<00:00, 392.93it/s]\n"
     ]
    }
   ],
   "source": [
    "all_scores = defaultdict(list)\n",
    "for u,i,d in tqdm(hoursValid_with_negatives):\n",
    "    pred = predict_would_play(u,i)\n",
    "    all_scores[u].append((pred,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85aeedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19998/19998 [00:00<00:00, 1572952.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Testing on the set I created earlier with the negative samples\n",
    "all_scores = {u:sorted(l,reverse=True) for u, l in all_scores.items()}\n",
    "top_half_scores = {}\n",
    "for key, lst in all_scores.items():\n",
    "    mu = np.mean([p[0] for p in lst])\n",
    "    \n",
    "    # Find the breakpoint\n",
    "    index = next((i for i, p in enumerate(lst) if p[0] <= mu), len(lst))\n",
    "    top_half_scores[key] = {p[1] for p in lst[:index]}\n",
    "    \n",
    "predictionss = []\n",
    "for u, g, d in tqdm(hoursValid_with_negatives):\n",
    "    if g in top_half_scores[u]:\n",
    "        # Predict 1 for items with score above the mean\n",
    "        predictionss.append(1)\n",
    "    else:\n",
    "        # Predict 0 otherwise\n",
    "        predictionss.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db11fcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BPR with learning_rate=0.1, K=5, and lambda=1e-05 is 0.7494749474947495\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc = np.mean(predictionss == labels)\n",
    "print(f'Accuracy of BPR with learning_rate={LR}, K={K}, and lambda={lamb} is {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cedf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Played.csv\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69a3417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = defaultdict(list)\n",
    "test_set = []\n",
    "for l in open(\"pairs_Played.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    p = predict_would_play(u,g)\n",
    "    all_scores[u].append((p,g))\n",
    "    test_set.append((u,g,{}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2495128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:00<00:00, 767491.74it/s]\n"
     ]
    }
   ],
   "source": [
    "all_scores = {u:sorted(l,reverse=True) for u, l in all_scores.items()}\n",
    "top_half_scores = {}\n",
    "for key, lst in all_scores.items():\n",
    "    mu = np.mean([p[0] for p in lst])\n",
    "    index = next((i for i, p in enumerate(lst) if p[0] <= mu), len(lst))\n",
    "    top_half_scores[key] = {p[1] for p in lst[:index]}\n",
    "    \n",
    "\n",
    "pred = 0\n",
    "for u, g, d in tqdm(test_set):\n",
    "    if g in top_half_scores[u]:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4c521f9-c77f-43c9-ba5f-8aa7d48c5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Hours played prediction                        #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8026d643-8844-4801-9a91-60fc43dad307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypred):\n",
    "    differences = [(x-y)**2 for x,y in zip(ypred,y)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af710723-5d68-4371-9c75-216f98b1f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHours = [r[2]['hours_transformed'] for r in hoursTrain]\n",
    "globalAverage = sum(trainHours) * 1.0 / len(trainHours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7422b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoursPerUser = defaultdict(list)\n",
    "hoursPerItem = defaultdict(list)\n",
    "for u,g,d in allHours:\n",
    "    r = d['hours_transformed']\n",
    "    hoursPerUser[u].append((g,r))\n",
    "    hoursPerItem[g].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58ae37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHours = [r[2]['hours_transformed'] for r in allHours]\n",
    "globalAverage = sum(trainHours) * 1.0 / len(trainHours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ea4d9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.717863918924211"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da72073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "per = int(len(allHours) * 0.9)\n",
    "Train = allHours[:per]\n",
    "Valid = allHours[per:]\n",
    "assert (len(Train) + len(Valid)) == len(allHours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d1a7a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE (average only) = 5.315913624424781\n"
     ]
    }
   ],
   "source": [
    "validMSE = 0\n",
    "for u,g,d in hoursValid:\n",
    "    r = d['hours_transformed']\n",
    "    se = (r - globalAverage)**2\n",
    "    validMSE += se\n",
    "\n",
    "validMSE /= len(hoursValid)\n",
    "\n",
    "print(\"Validation MSE (average only) = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aba08b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(lamb):\n",
    "    newAlpha = 2.5\n",
    "    for u,g,d in allHours:\n",
    "        r = d['hours_transformed']\n",
    "        newAlpha += r - (betaU[u] + betaI[g])\n",
    "    alpha = newAlpha / len(allHours)\n",
    "    for u in hoursPerUser:\n",
    "        newBetaU = 0\n",
    "        for g,r in hoursPerUser[u]:\n",
    "            newBetaU += r - (alpha + betaI[g])\n",
    "        betaU[u] = newBetaU / (lamb + len(hoursPerUser[u]))\n",
    "    for g in hoursPerItem:\n",
    "        newBetaI = 0\n",
    "        for u,r in hoursPerItem[g]:\n",
    "            newBetaI += r - (alpha + betaU[u])\n",
    "        betaI[g] = newBetaI / (lamb + len(hoursPerItem[g]))\n",
    "    mse = 0\n",
    "    for u,g,d in allHours:\n",
    "        r = d['hours_transformed']\n",
    "        prediction = alpha + betaU[u] + betaI[g]\n",
    "        mse += (r - prediction)**2\n",
    "    regularizer = 0\n",
    "    for u in betaU:\n",
    "        regularizer += betaU[u]**2\n",
    "    for g in betaI:\n",
    "        regularizer += betaI[g]**2\n",
    "    mse /= len(allHours)\n",
    "    return mse, mse + lamb*regularizer, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f567ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective after 20 iterations = 23872.187687423386\n",
      "MSE after 20 iterations = 2.784333973113838\n",
      "Objective after 40 iterations = 23673.150046572333\n",
      "MSE after 40 iterations = 2.7835177440376486\n"
     ]
    }
   ],
   "source": [
    "lamb = 5\n",
    "betaU = {}\n",
    "betaI = {}\n",
    "for u in hoursPerUser:\n",
    "    betaU[u] = 0\n",
    "\n",
    "for g in hoursPerItem:\n",
    "    betaI[g] = 0\n",
    "mse,objective,alpha = iterate(lamb)\n",
    "newMSE,newObjective,alpha = iterate(lamb)\n",
    "iterations = 2\n",
    "while iterations < 10 or objective - newObjective > 0.05:\n",
    "    mse, objective = newMSE, newObjective\n",
    "    newMSE, newObjective, alpha = iterate(lamb)\n",
    "    iterations += 1\n",
    "    if iterations % 20 == 0:\n",
    "        print(\"Objective after \"\n",
    "            + str(iterations) + \" iterations = \" + str(newObjective))\n",
    "        print(\"MSE after \"\n",
    "            + str(iterations) + \" iterations = \" + str(newMSE))\n",
    "    if abs(newMSE - mse) < 0.00001:\n",
    "        print(f\"Converged at iteration {iterations}\")\n",
    "        print(f\"Converged with oldMSE = {mse}\")\n",
    "        print(f\"Converged with newMSE = {newMSE}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c30efe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE = 2.74830185348576\n"
     ]
    }
   ],
   "source": [
    "validMSE = 0\n",
    "for u,g,d in hoursValid:\n",
    "    r = d['hours_transformed']\n",
    "    bu = 0\n",
    "    bi = 0\n",
    "    if u in betaU:\n",
    "        bu = betaU[u]\n",
    "    if g in betaI:\n",
    "        bi = betaI[g]\n",
    "    prediction = alpha + bu + bi\n",
    "    validMSE += (r - prediction)**2\n",
    "ß\n",
    "validMSE /= len(hoursValid)\n",
    "print(\"Validation MSE = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7e514ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    # Logic...\n",
    "    bu = 0\n",
    "    bi = 0\n",
    "    if u in betaU:\n",
    "        bu = betaU[u]\n",
    "    if g in betaI:\n",
    "        bi = betaI[g]\n",
    "        \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(alpha + bu + bi) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94a597a6-518d-441e-becb-6ccd33cbaaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Bayesian_Personalized_ranking.ipynb to script\n",
      "[NbConvertApp] Writing 11159 bytes to BPR.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script Bayesian_Personalized_ranking.ipynb --output 'BPR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55abf31-26c5-477a-bf2f-702bcaa899d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
